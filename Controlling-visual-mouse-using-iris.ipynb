{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04b65750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import rshift\n",
    "import cv2 as cv \n",
    "import numpy as np\n",
    "import mediapipe as mp \n",
    "import pyautogui\n",
    "from gaze_tracking import GazeTracking\n",
    "\n",
    "gaze = GazeTracking()\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "LEFT_EYE =[ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]\n",
    "RIGHT_EYE=[ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ] \n",
    "LEFT_IRIS = [474,475, 476, 477]\n",
    "RIGHT_IRIS = [469, 470, 471, 472]\n",
    "cap = cv.VideoCapture(0)\n",
    "pX, pY = 0, 0  # Previous x and y location\n",
    "cX, cY = 0, 0  # Current x and y location\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ") as face_mesh:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        gaze.refresh(frame)\n",
    "        frame = gaze.annotated_frame()\n",
    "        left_pupil = gaze.pupil_left_coords()\n",
    "        right_pupil = gaze.pupil_right_coords()\n",
    "        \n",
    "        #frame = cv.flip(frame, 1)\n",
    "        rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        img_h, img_w = frame.shape[:2]\n",
    "        results = face_mesh.process(rgb_frame)\n",
    "        if results.multi_face_landmarks:\n",
    "            mesh_points=np.array([np.multiply([p.x, p.y], [img_w, img_h]).astype(int) for p in \n",
    "                                  results.multi_face_landmarks[0].landmark])\n",
    "            (l_cx, l_cy), l_radius = cv.minEnclosingCircle(mesh_points[LEFT_IRIS])\n",
    "            (r_cx, r_cy), r_radius = cv.minEnclosingCircle(mesh_points[RIGHT_IRIS])\n",
    "            center_left = np.array([l_cx, l_cy], dtype=np.int32)\n",
    "            center_right = np.array([r_cx, r_cy], dtype=np.int32)\n",
    "            cv.circle(frame, center_left, int(l_radius), (255,0,255), 1, cv.LINE_AA)\n",
    "            cv.circle(frame, center_right, int(r_radius), (255,0,255), 1, cv.LINE_AA)\n",
    "            \n",
    "            x3 = np.interp(l_cx, (75, 640 - 75), (0, 1920))  # Converts the width of the window relative to the screen width\n",
    "            y3 = np.interp(l_cy, (75, 480 - 75), (0, 1080))  # Converts the height of the window relative to the screen height\n",
    "            \n",
    "            cX = pX + (x3 - pX) / 7  # Stores previous x locations to update current x location\n",
    "            cY = pY + (y3 - pY) / 7  # Stores previous y locations to update current y location\n",
    "            \n",
    "            \n",
    "            pyautogui.moveTo(1920 - cX, cY)\n",
    "            pX, pY = cX, cY  # Stores the current x and y location as previous x and y location for next loop\n",
    "            \n",
    "        if left_pupil==None and right_pupil==None:\n",
    "            pyautogui.click()\n",
    "            \n",
    "        cv.imshow('img', frame)\n",
    "        key = cv.waitKey(1)\n",
    "        if key ==ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
